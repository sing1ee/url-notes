
## [HippoRAG 2发布，GraphRAG退位~](https://mp.weixin.qq.com/s/AcvZH3Aj2CfXO3QBOFkybw)
- Time: 2025/3/1 08:31:12
- Note: RAG：HippoRAG2，比 PAPTOR，GraphRAG，LightRAG，HippoRAG 都要好。

## [nvidia/NV-Embed-v2 · Hugging Face](https://huggingface.co/nvidia/NV-Embed-v2)
- Time: 2025/3/1 08:35:04
- Note: 完整的 RAG 框架：嵌入，重排等

## [最近开源的几个视频生成模型](https://mp.weixin.qq.com/s/lslc-RFdCbApKLLJURfs7A)
- Time: 2025/3/1 21:27:40
- Note: 文本生成视频，图片生成视频

## [BinBashBanana/gfiles: Collection of HTML5 and flash games, plus webretro](https://github.com/BinBashBanana/gfiles)
- Time: 2025/3/2 21:44:31
- Note: 网页游戏合集

## [Exa Websets](https://websets.exa.ai/)
- Time: 2025/3/3 15:15:05
- Note: Exa 的 AI 搜索工具 Websets 上线，可以进行非常复杂的搜索，以数据表的形式呈现，比如要求他给出美国市值前 50 的 AI 创业公司 CEO 信息，这个搜索工具可以-次性阅读超过 1000 个网页

## [VividTalk: One-Shot Audio-Driven Talking Head Generation Based 3D Hybrid Prior](https://humanaigc.github.io/vivid-talk/)
- Time: 2025/3/4 09:18:46
- Note: 音频驱动的头部数字人视频生成：基于 3D 混合先验的一次性音频驱动头部生成

## [Henry-23/VideoChat: 实时语音交互数字人，支持端到端语音方案（GLM-4-Voice - THG）和级联方案（ASR-LLM-TTS-THG）。可自定义形象与音色，无须训练，支持音色克隆，首包延迟低至3s。Real-time voice interactive digital human, supporting end-to-end voice solutions (GLM-4-Voice - THG) and cascaded solutions (ASR-LLM-TTS-THG). Customizable appearance and voice, supporting voice cloning, with initial package delay as low as 3s.](https://github.com/Henry-23/VideoChat?tab=readme-ov-file)
- Time: 2025/3/4 11:42:04
- Note: 实时语音交互数字人

## [Linly-Talker/README_zh.md at main · Kedreamix/Linly-Talker](https://github.com/Kedreamix/Linly-Talker/blob/main/README_zh.md)
- Time: 2025/3/4 12:12:00
- Note: 数字人智能对话系统

## [TMElyralab/MuseTalk: MuseTalk: Real-Time High Quality Lip Synchorization with Latent Space Inpainting](https://github.com/TMElyralab/MuseTalk)
- Time: 2025/3/4 13:50:34
- Note: MuseTalk是一个实时高质量的音频驱动的唇部同步模型。它可以修改未见过的人脸以匹配输入的音频,支持多种语言,并且可以在NVIDIA Tesla V100上实现30fps+的实时推理。该项目还提供了一个完整的虚拟人解决方案,包括MuseV和MusePose。

## [xxnuo/MTranServer: Low-resource, fast, and privately self-host free version of Google Translate - 低占用速度快可私有部署的自由版 Google 翻译](https://github.com/xxnuo/MTranServer)
- Time: 2025/3/4 14:23:19
- Note: 一个超低资源消耗超快的离线翻译服务器，仅需 CPU + 1G 内存即可运行，无需 GPU。单个请求平均响应时间 50ms。支持全世界主要语言的翻译。

## [Reddit 出海指南：从 Build in Public 到 Build in Community](https://mp.weixin.qq.com/s/pQ_PzwoP7_Db51guGerIhQ)
- Time: 2025/3/4 14:23:46
- Note: reddit 运营

## [RVC-Boss/GPT-SoVITS: 1 min voice data can also be used to train a good TTS model! (few shot voice cloning)](https://github.com/RVC-Boss/GPT-SoVITS)
- Time: 2025/3/4 14:46:10
- Note: 开源效果非常好的声音克隆模型

## [Fictionarry/ER-NeRF: [ICCV'23] Efficient Region-Aware Neural Radiance Fields for High-Fidelity Talking Portrait Synthesis](https://github.com/Fictionarry/ER-NeRF)
- Time: 2025/3/4 14:59:47
- Note: 这个项目是一个高保真的人物肖像合成系统,基于区域感知的神经辐射场(ER-NeRF)。它可以从视频和音频输入中生成逼真的人物动画。

## [yerfor/GeneFace: GeneFace: Generalized and High-Fidelity 3D Talking Face Synthesis; ICLR 2023; Official code](https://github.com/yerfor/GeneFace)
- Time: 2025/3/5 13:02:17
- Note: 音频驱动视频生成

## [jixiaozhong/Sonic: Official implementation of "Sonic: Shifting Focus to Global Audio Perception in Portrait Animation"](https://github.com/jixiaozhong/Sonic?tab=readme-ov-file)
- Time: 2025/3/5 13:08:03
- Note: 图片，音频驱动的 视频生成。效果最好。

## [Zejun-Yang/AniPortrait: AniPortrait: Audio-Driven Synthesis of Photorealistic Portrait Animation](https://github.com/Zejun-Yang/AniPortrait)
- Time: 2025/3/5 13:10:10
- Note: 音频+图片，生成视频，也挺强的。

## [INFP: Audio-Driven Interactive Head Generation in Dyadic Conversations](https://grisoon.github.io/INFP/)
- Time: 2025/3/5 13:13:44
- Note: 语音+图片 生成 视频，效果太好了

## [HunyuanVideo-I2V/README_zh.md at main · Tencent/HunyuanVideo-I2V](https://github.com/Tencent/HunyuanVideo-I2V/blob/main/README_zh.md)
- Time: 2025/3/6 20:13:10
- Note: 混元 image to video，带风格提示

## [hkdobrev/cleanmac: Clean your macOS with a script, not an expensive app](https://github.com/hkdobrev/cleanmac)
- Time: 2025/3/7 15:50:42
- Note: mac 清理

## [tonghohin/screen-sharing: Share your screen with one simple room code. No downloads or sign-ups required.](https://github.com/tonghohin/screen-sharing)
- Time: 2025/3/7 15:51:54
- Note: 这是一个基于 Next.js、WebRTC 和 PeerJS 构建的实时屏幕共享应用程序。它允许用户创建或加入房间,并与他人即时共享屏幕和音频。

## [allenai/olmocr: Toolkit for linearizing PDFs for LLM datasets/training](https://github.com/allenai/olmocr)
- Time: 2025/3/7 15:52:32
- Note: olmOCR 是一个用于训练语言模型处理野生 PDF 文档的工具包。它包括了一系列功能,如使用 ChatGPT 的提示策略进行高质量的自然文本解析、用于比较不同管道版本的并排评估工具包、基于语言和 SEO 垃圾的过滤器,以及用于微调 Qwen2-VL 和 Molmo-O 的代码。此外,它还提供了通过微调模型处理大量 PDF 的功能,以及用于查看从 PDF 生成的 Dolma 文档的工具。



## [ASLP-lab/DiffRhythm: Di♪♪Rhythm: Blazingly Fast and Embarrassingly Simple End-to-End Full-Length Song Generation with Latent Diffusion](https://github.com/ASLP-lab/DiffRhythm)
- Time: 2025/3/7 15:53:24
- Note: DiffRhythm是一个开源的基于扩散的音乐生成模型,可以创作出完整的歌曲。它结合了"Diff"(扩散架构)和"Rhythm"(音乐创作)两个关键词,中文名"谛韵"也体现了对音频感知和音乐魅力的关注。

## [Xiao Hong Red：肖弘其人 - 立委NLP频道](https://liweinlp.com/13055)
- Time: 2025/3/10 08:53:17
- Note: "用博弈的方式思考，而不是逻辑推理" 肖弘对创业思维的总结堪称清奇：不要用逻辑推理（"百度有最好的算法工程师，所以百度一定会把推荐做好"），而要用博弈思维（"因为某个玩家的加入，整个游戏规则都变了"）。逻辑推理里面没有字节什么事儿，博弈思维却可以容纳 Liang Wenfeng 与 Xiao Hong 这些新的玩家。  这就像下棋，不是简单地推导"如果我走这步，对方一定会走那步"，而是要考虑"因为我走了这步，对方可能会改变整个策略"。  在这种思维下，即使面对巨头林立的竞争环境，创业者也能找到自己的机会——不是通过线性推导（那样只会得出"一切都是巨头的机会"的悲观结论），而是通过成为改变游戏规则的变量。  就是说，Sam 鼓吹的头部大模型厂家碾压一切的前景最多只是一半的真理。模型与应用各司其长的空间大概率会长久存在。

## [肖弘与Manus：AI Agent 的实战方法论 - 立委NLP频道](https://liweinlp.com/13057)
- Time: 2025/3/10 10:59:41
- Note: 但是系统界面真的看就能理解吗？OA除外，我说的是业务系统，LLM有这个本事？这还涉及到增量，今后的新系统，难道就为了给agent看UI而设计UI？反正人是不看了，看agent就够了。我觉得到时候一定会有一个裸api标准。而且垂域也会细化自己这个部位。就像XML和各个垂域的标记语言一样。

## [Crossing the uncanny valley of conversational voice](https://www.sesame.com/research/crossing_the_uncanny_valley_of_voice#demo)
- Time: 2025/3/11 20:41:55
- Note: 真实的端到端语言模型。

## [从深圳去香港不去网点柜台最快开通汇丰银行账号全流程攻略分享](https://mp.weixin.qq.com/s/V3KFdngsCnSybIWfRnd-lQ)
- Time: 2025/3/11 20:43:17
- Note: 出海收款，香港个人
